## 问题回顾
- 多处模型配置与参数分散且不一致：`services/ai-service.js`、`popup/popup.js`、`background.js` 存在模型名、端点、`temperature/maxTokens` 等差异。
- 接口契约不匹配：`AIGrader` 调用 `AIService.chat(...)`，但 `AIService` 未实现；`AIScoringEngine`/`services/index.js` 以函数形式实例化类（未使用 `new`）。
- 运行时关键字段未赋值：`AIService` 使用 `this.apiEndpoint`、`this.apiKey`、`this.apiType`，但未在 `configure` 中正确设置，导致通用聊天路径可能直接失败；仅图像评分路径使用 `modelConfig.endpoint` 能成功。
- 参数适配不完整：不同厂商的字段（如 Gemini 的 `topK/maxOutputTokens`）未统一映射；并发/限速字段未生效；无 token 计数与输入截断策略。

## 改造目标
1. 单一真源：集中模型注册、端点与参数适配，消除重复与漂移。
2. 契约统一：统一服务接口，保证 `AIGrader/AIScoringEngine` 与 `AIService` 一致。
3. 稳健性：补全必需的运行态字段、容错与重试、并发控制与节流、输入长度管理。
4. 可维护：UI 只读展示/编辑集中配置，后台真正生效处仅一处。

## 分步实施
### 第1步：集中模型注册
- 在 `services/ai-service.js` 定义并导出 `modelRegistry`（提供商、端点、是否视觉、参数上限）。
- `popup/background` 读取该注册表生成默认设置（去掉硬编码端点与参数）。

### 第2步：修复 `AIService` 运行态
- 在 `configure` 中：
  - 解析 `settings`，设置 `this.apiType/this.currentModel/this.apiEndpoint`；
  - 统一 `apiKey` 获取方式（仅用 `getApiKey(provider)`）；
  - 提供 `setCurrentModel(modelKey)` 自动联动 `apiType/apiEndpoint`。
- 补充通用 `chat(messages, options)` 方法，内部按 `apiType` 路由至 `callOpenAI/Gemini/Claude`；确保使用集中端点与参数映射。

### 第3步：修复调用方契约
- `AIGrader`：改为调用 `aiService.chat(...)`（保持其现有用法但落地实现）；
- `AIScoringEngine` 与 `services/index.js`：使用 `new AIService()`/`new AIScoringEngine()` 正确实例化类。

### 第4步：参数适配器与长度管理
- 建立参数映射：
  - OpenAI：`temperature/top_p/max_tokens`
  - Gemini：`temperature/topP/topK/maxOutputTokens`
  - Qwen/GLM：`temperature/top_p/max_tokens`（按各自文档校准）
- 引入输入长度守卫：简单版使用字符上限，后续可接入 token 计数库；超长时截断并记录提示。

### 第5步：并发与限速生效
- 在批量评分调用处应用 `utils/helpers.pMap(limit=concurrentRequests)`；
- 使用 `rateLimitDelay` 做简单节流；与重试 `callWithRetry` 组合。

### 第6步：验证与回归
- 为通用 `chat`、各厂商调用、图像评分、双模型验证路径编写最小自测（模拟响应/接口探测）。
- UI 读取集中配置后，验证默认模型、端点与参数一致；检查 `settings` 升级兼容。

### 第7步：可选增强
- 流式响应支持（OpenAI/GLM 先行）；
- 更精细的 token 计数与截断；
- 真实 `Claude`/`Azure OpenAI` 适配与连接测试完善。

## 交付物
- 统一模型注册与参数映射；
- 修复后的 `AIService` 与调用方；
- 最小验证脚本与操作说明；
- 设置迁移逻辑（避免旧设置失效）。

## 风险与规避
- 设置兼容：提供迁移器，将旧 `settings` 字段映射到新结构；
- 端点变更：以注册表为唯一来源，避免 UI 写死；
- 厂商差异：参数映射做最小闭包，后续按需扩展。